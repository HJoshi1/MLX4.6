{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNjaY1xcgbg6kjU+1oRxrEg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d-fVHPgLcFOh","executionInfo":{"status":"ok","timestamp":1712577096011,"user_tz":-60,"elapsed":1539,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"11083821-8ca9-4012-d571-4187efe3506b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","source":["import os\n","import ast\n","import pandas as pd\n","import sentencepiece as spm\n"],"metadata":{"id":"kxIiNtTGcOmY","executionInfo":{"status":"ok","timestamp":1712579050719,"user_tz":-60,"elapsed":223,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["# Paths\n","os.chdir('/content/gdrive/My Drive/Colab Notebooks/Multimodal Transformers for Image Captioning/')\n","\n","annotations_csv = 'flickr_annotations_30k.csv'\n","captions_corpus = 'flickr_annotations_corpus.txt'\n","spm_model = 'spm.model'\n"],"metadata":{"id":"zSvNU96ocYyV","executionInfo":{"status":"ok","timestamp":1712578645985,"user_tz":-60,"elapsed":5,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# Preview the Flickr8k captions\n","annotations = pd.read_csv(annotations_csv)\n","print(annotations.head())\n","print(annotations.info())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97OiOX9RoVt-","executionInfo":{"status":"ok","timestamp":1712578647860,"user_tz":-60,"elapsed":450,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"3b885cc1-230f-49ac-c3d1-cd23907e56dc"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                                                                                                                                                                                                                                                                                    raw  \\\n","0                            [\"Two young guys with shaggy hair look at their hands while hanging out in the yard.\", \"Two young, White males are outside near many bushes.\", \"Two men in green shirts are standing in a yard.\", \"A man in a blue shirt standing in a garden.\", \"Two friends enjoy time spent together.\"]   \n","1                                                                 [\"Several men in hard hats are operating a giant pulley system.\", \"Workers look down from up above on a piece of equipment.\", \"Two men working on a machine wearing hard hats.\", \"Four men on top of a tall structure.\", \"Three men on a large rig.\"]   \n","2                             [\"A child in a pink dress is climbing up a set of stairs in an entry way.\", \"A little girl in a pink dress going into a wooden cabin.\", \"A little girl climbing the stairs to her playhouse.\", \"A little girl climbing into a wooden playhouse.\", \"A girl going into a wooden building.\"]   \n","3  [\"Someone in a blue shirt and hat is standing on stair and leaning against a window.\", \"A man in a blue shirt is standing on a ladder cleaning a window.\", \"A man on a ladder cleans the window of a tall building.\", \"Man in blue shirt and jeans on ladder cleaning windows\", \"A man on a ladder cleans a window\"]   \n","4                                                      [\"Two men, one in a gray shirt, one in a black shirt, standing near a stove.\", \"Two guy cooking and joking around with the camera.\", \"Two men in a kitchen cooking food on a stove.\", \"Two men are at the stove preparing food.\", \"Two men are cooking a meal.\"]   \n","\n","                sentids  split        filename  img_id  \n","0       [0, 1, 2, 3, 4]  train  1000092795.jpg       0  \n","1       [5, 6, 7, 8, 9]  train    10002456.jpg       1  \n","2  [10, 11, 12, 13, 14]  train  1000268201.jpg       2  \n","3  [15, 16, 17, 18, 19]  train  1000344755.jpg       3  \n","4  [20, 21, 22, 23, 24]  train  1000366164.jpg       4  \n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 31014 entries, 0 to 31013\n","Data columns (total 5 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   raw       31014 non-null  object\n"," 1   sentids   31014 non-null  object\n"," 2   split     31014 non-null  object\n"," 3   filename  31014 non-null  object\n"," 4   img_id    31014 non-null  int64 \n","dtypes: int64(1), object(4)\n","memory usage: 1.2+ MB\n","None\n"]}]},{"cell_type":"code","source":["# Read the CSV captions file into a DataFrame\n","\n","captions = annotations.raw\n","\n","# Create or open a text file for writing\n","with open(captions_corpus, 'w') as f:\n","    # Iterate over each row in the DataFrame\n","    for row in captions:\n","        # Assuming each row contains a single string\n","        sentences = row.strip('[]\"').split('\", \"')\n","        # Write each sentence to the output text file\n","        for sentence in sentences:\n","                f.write(sentence.strip() + '\\n')\n"],"metadata":{"id":"X7hxHuLuiJfo","executionInfo":{"status":"ok","timestamp":1712579858756,"user_tz":-60,"elapsed":223,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["vocab_size = 16000\n","model_prefix = 'spm'\n","\n","# Train SentencePiece model\n","spm.SentencePieceTrainer.train(f'--pad_id=0 --bos_id=1 --eos_id=2 --unk_id=3 --input={captions_corpus} --model_prefix={model_prefix} --vocab_size={vocab_size}')\n"],"metadata":{"id":"79eHrO49c8jo","executionInfo":{"status":"ok","timestamp":1712580020858,"user_tz":-60,"elapsed":218,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["# Create segmenter instance and load the model file\n","sp = spm.SentencePieceProcessor()\n","sp.load(spm_model)\n","\n","# Get the actual vocabulary size\n","vocab_size = sp.get_piece_size()\n","\n","# Print the actual vocabulary size\n","print(\"Actual vocabulary size:\", vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NOv6pAB7c_kk","executionInfo":{"status":"ok","timestamp":1712580048262,"user_tz":-60,"elapsed":385,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"04eba3b7-5069-4fe5-fa3a-a5b23f55c8d4"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Actual vocabulary size: 16000\n"]}]},{"cell_type":"code","source":["# Load pre-trained tokenizer\n","sp = spm.SentencePieceProcessor()\n","sp.load(spm_model)\n","\n","# Get the actual vocabulary size\n","vocab_size = sp.get_piece_size()\n","print(sp.id_to_piece(0))\n","print(sp.id_to_piece(1))\n","print(sp.id_to_piece(2))\n","\n","# Print the actual vocabulary size\n","print(\"Actual vocabulary size:\", vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNjdJFKggx2I","executionInfo":{"status":"ok","timestamp":1712580059301,"user_tz":-60,"elapsed":212,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"8b3083fc-08ab-4096-b045-58cc24d73567"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["<pad>\n","<s>\n","</s>\n","Actual vocabulary size: 16000\n"]}]}]}